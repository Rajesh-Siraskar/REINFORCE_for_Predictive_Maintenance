{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6ba8c-69f8-42ec-9d12-2bb6e82d9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import milling_tool_environment\n",
    "import utilities\n",
    "from milling_tool_environment import MillingTool_SS_V2, MillingTool_MS_V2\n",
    "from utilities import compute_metrics, compute_metrics_simple, write_metrics_report, store_results, plot_learning_curve, single_axes_plot\n",
    "from utilities import two_axes_plot, two_variable_plot, plot_error_bounds, test_script, write_test_results, downsample\n",
    "from reinforce_classes import PolicyNetwork, Agent\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "\n",
    "dt = datetime.datetime.now()\n",
    "dt_d = dt.strftime('%d-%b-%Y')\n",
    "dt_t = dt.strftime('%H_%M_%S')\n",
    "dt_m = dt.strftime('%H%M')\n",
    "\n",
    "# Version name: <Ver.No>_Sim_<N or W>NB_<episodes>_test-run\n",
    "# Data Files: Simulated_Dasic_2006_Tool_Wear_Model. Threshold 3mm\n",
    "# PHM:        PHM_C01_MultiStateEnv_0p12; PHM_C04_MultiStateEnv_0p0975; PHM_C06_MultiStateEnv_0p13\n",
    "\n",
    "ENVIRONMENT_INFO = 'PHM 2006. Single-var state V2.'\n",
    "DATA_FILE = 'data\\PHM_C06_MultiStateEnv_0p13.csv'\n",
    "WEAR_THRESHOLD = 0.12 # mm\n",
    "ADD_NOISE = 1e3 # 0 for no noise. Factor to apply on np.random.rand(). For e.g. 1e2 or 1e3 are factors for higher and lower noise. \n",
    "BREAKDOWN_CHANCE = 0.05 # Recommended: 0.05 = 5%\n",
    "EPISODES = 1200 # Train for N episodes. # Suggested 600\n",
    "\n",
    "## Read data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "n_records = len(df.index)\n",
    "# MILLING_OPERATIONS_MAX = 800\n",
    "MILLING_OPERATIONS_MAX = n_records-1 # Suggested 300\n",
    "# MILLING_OPERATIONS_MAX = 800\n",
    "\n",
    "if ADD_NOISE == 1e3 and BREAKDOWN_CHANCE == 0.05:\n",
    "    lnoise = 'LowNBD'\n",
    "elif ADD_NOISE == 1e2  and BREAKDOWN_CHANCE == 0.10:\n",
    "    lnoise = 'HighNBD'\n",
    "elif ADD_NOISE <= 0 and BREAKDOWN_CHANCE == 0:\n",
    "    lnoise = 'NoNBD'\n",
    "else:\n",
    "    lnoise = 'ArbNBD'\n",
    "\n",
    "VERSION = f'PHM-C06_{lnoise}_{WEAR_THRESHOLD}_{EPISODES}_{MILLING_OPERATIONS_MAX}'\n",
    "\n",
    "METRICS_METHOD = 'weighted' # average method = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’} \n",
    "TEST_INFO = 'Sampled from training data'\n",
    "TEST_CASES = 40\n",
    "TEST_ROUNDS = 5\n",
    "# Milling operation constants\n",
    "WEAR_THRESHOLD_NORMALIZED = 0.0 # normalized to the max wear threshold\n",
    "\n",
    "# Policy network learning parameters\n",
    "gamma = 0.99\n",
    "alpha = 0.01\n",
    "\n",
    "RESULTS_FOLDER = 'results/18-May-2023'\n",
    "CONSOLIDATED_METRICS_FILE = f'{RESULTS_FOLDER}/CONSOLIDATED_METRICS.csv'\n",
    "RESULTS_FILE = f'{RESULTS_FOLDER}/{VERSION}_test_results_{dt_d}_{dt_m}.csv'\n",
    "METRICS_FILE = f'{RESULTS_FOLDER}/{VERSION}_metrics.csv'\n",
    "\n",
    "# RESULTS_FILE = f'results/13-May-2023/{VERSION}_test_results_{dt_d}-{dt_m}.csv'\n",
    "# METRICS_FILE = f'results/13-May-2023/{VERSION}_metrics_{dt_d}-{dt_m}.csv'\n",
    "\n",
    "print('\\n -- Columns added to results file ', RESULTS_FILE)\n",
    "results = ['Date', 'Time', 'Round', 'Environment', 'Training_data', 'Wear_Threshold', 'Test_data', 'Algorithm', 'Episodes', 'Normal_cases', 'Normal_error', \n",
    "           'Replace_cases', 'Replace_error', 'Overall_error', \n",
    "           'Wtd_Precision', 'Wtd_Recall', 'F_Beta_0_5', 'F_Beta_0_75', 'F_1_Score']\n",
    "write_test_results(results, RESULTS_FILE)\n",
    "\n",
    "# Normalizing entire df with min-max scaling\n",
    "WEAR_MIN = df['tool_wear'].min() \n",
    "WEAR_MAX = df['tool_wear'].max()\n",
    "WEAR_THRESHOLD_NORMALIZED = (WEAR_THRESHOLD-WEAR_MIN)/(WEAR_MAX-WEAR_MIN)\n",
    "df_normalized = (df-df.min())/(df.max()-df.min())\n",
    "df_normalized['ACTION_CODE'] = df['ACTION_CODE']\n",
    "print(f'Tool wear data imported ({len(df.index)} records). WEAR_THRESHOLD_NORMALIZED: {WEAR_THRESHOLD_NORMALIZED:4.3f} \\n\\n')\n",
    "\n",
    "# Visualize the data\n",
    "# df.plot(figsize = (10, 6))\n",
    "\n",
    "x = [n for n in range(n_records)]\n",
    "y1 = df['tool_wear'].values.tolist()\n",
    "y2 = df['ACTION_CODE'].values.tolist()\n",
    "wear_plot = f'{RESULTS_FOLDER}/{VERSION}_wear_plot.png'\n",
    "title=f'Tool Wear (mm) data\\n{VERSION}'\n",
    "two_axes_plot(x, y1, y2, title=title, x_label='Time', y1_label='Tool Wear (mm)', y2_label='Action code (1=Replace)', xticks=20, file=wear_plot, threshold=WEAR_THRESHOLD)\n",
    "\n",
    "### Environment\n",
    "env = MillingTool_SS_V2(df_normalized, WEAR_THRESHOLD_NORMALIZED, MILLING_OPERATIONS_MAX, ADD_NOISE, BREAKDOWN_CHANCE, 1.0, -1.0, -100.0)\n",
    "\n",
    "### Main loop\n",
    "rewards_history = []\n",
    "loss_history = []\n",
    "training_stats = []\n",
    "\n",
    "input_dim = env.observation_space.shape[0]\n",
    "output_dim = env.action_space.n\n",
    "\n",
    "agent_RF = Agent(input_dim, output_dim, alpha, gamma)\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    state = env.reset()\n",
    "\n",
    "    # Sample a trajectory\n",
    "    for t in range(MILLING_OPERATIONS_MAX): # Max. milling operations desired\n",
    "        action = agent_RF.act(state)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        agent_RF.rewards.append(reward)\n",
    "        #env.render()\n",
    "        if done:\n",
    "            # print('** DONE **', info)\n",
    "            break\n",
    "\n",
    "    # Learn during this episode \n",
    "    loss = agent_RF.learn() # train per episode\n",
    "    total_reward = sum(agent_RF.rewards)\n",
    "\n",
    "    # Record statistics for this episode\n",
    "    rewards_history.append(total_reward)\n",
    "    loss_history.append(loss.item()) # Extract values from list of torch items for plotting\n",
    "\n",
    "    # On-policy - so discard all data \n",
    "    agent_RF.onpolicy_reset()\n",
    "\n",
    "    if (episode%100 == 0):\n",
    "        # print(f'[{episode:04d}] Loss: {loss:>10.2f} | Reward: {total_reward:>10.2f} | Ep.length: {env.ep_length:04d}')\n",
    "        print(f'[{episode:04d}] Loss: {loss:>10.2e} | Reward: {total_reward:>10.2e} | Ep.length: {env.ep_length:04d}')\n",
    "        \n",
    "x = [i for i in range(EPISODES)]\n",
    "\n",
    "## Moving average for rewards\n",
    "ma_window_size = 10\n",
    "# # Convert error array to pandas series\n",
    "rewards = pd.Series(rewards_history)\n",
    "windows = rewards.rolling(ma_window_size)\n",
    "moving_avg = windows.mean()\n",
    "moving_avg_lst = moving_avg.tolist()\n",
    "y1 = rewards\n",
    "y2 = moving_avg_lst\n",
    "\n",
    "filename = f'{RESULTS_FOLDER}/{VERSION}_Avg_episode_rewards.png'\n",
    "two_variable_plot(x, y1, y2, 'Avg. rewards per episode', VERSION, 'Episode', 'Avg. Rewards', 'Moving Avg.', 50, filename)\n",
    "\n",
    "# plot_error_bounds(x, y1)\n",
    "\n",
    "filename = f'{RESULTS_FOLDER}/{VERSION}_Episode_Length.png'\n",
    "single_axes_plot(x, env.ep_length_history, 'Episode length', VERSION, 'Episode', 'No of milling operations', 50, 0.0, filename)\n",
    "\n",
    "filename = f'{RESULTS_FOLDER}/{VERSION}_Tool_Replacements.png' \n",
    "single_axes_plot(x, env.ep_tool_replaced_history, 'Tool replacements per episode', VERSION, 'Episode', 'Replacements', 50, 0.0, filename)\n",
    "\n",
    "### TEST\n",
    "idx_replace_cases = df.index[df['ACTION_CODE'] >= 1.0]\n",
    "idx_normal_cases = df.index[df['ACTION_CODE'] < 1.0]\n",
    "\n",
    "print('\\n === REINFORCE model trained ===\\n')\n",
    "print(80*'-')\n",
    "print(f'Algorithm\\tNormal\\terr.%\\tReplace\\terr.%\\tOverall err.%')\n",
    "print(80*'-')\n",
    "for test_round in range(TEST_ROUNDS):\n",
    "    # Create test cases\n",
    "    idx_replace_cases = np.random.choice(idx_replace_cases, int(TEST_CASES/2), replace=False)\n",
    "    idx_normal_cases = np.random.choice(idx_normal_cases, int(TEST_CASES/2), replace=False)\n",
    "    test_cases = [*idx_normal_cases, *idx_replace_cases]\n",
    "    \n",
    "    results = test_script(METRICS_METHOD, test_round, df_normalized, 'REINFORCE', EPISODES, env, ENVIRONMENT_INFO, agent_RF, \n",
    "                          test_cases, TEST_INFO, DATA_FILE, WEAR_THRESHOLD, RESULTS_FILE)\n",
    "    write_test_results(results, RESULTS_FILE)\n",
    "    \n",
    "print(f'\\n- Test results written to file: {RESULTS_FILE}')\n",
    "\n",
    "algos = ['A2C','DQN','PPO']\n",
    "\n",
    "SB_agents = []\n",
    "\n",
    "for SB_ALGO in algos:\n",
    "    if SB_ALGO.upper() == 'A2C': agent_SB = A2C('MlpPolicy', env)\n",
    "    if SB_ALGO.upper() == 'DQN': agent_SB = DQN('MlpPolicy', env)\n",
    "    if SB_ALGO.upper() == 'PPO': agent_SB = PPO('MlpPolicy', env)\n",
    "    \n",
    "    print(f'\\n{SB_ALGO} - Training and Testing Stable-Baselines-3 {SB_ALGO} algorithm')\n",
    "    agent_SB.learn(total_timesteps=EPISODES)\n",
    "\n",
    "    SB_agents.append(agent_SB)\n",
    "    print(agent_SB)\n",
    "\n",
    "n = 0\n",
    "for agent_SB in SB_agents:\n",
    "    print(f'\\n\\n - Testing Stable-Baselines-3 {agent_SB}')\n",
    "    print(80*'-')\n",
    "    print(f'Algo.\\tNormal\\tErr.%\\tReplace\\tErr.%\\tOverall err.%')\n",
    "    print(80*'-')\n",
    "    for test_round in range(TEST_ROUNDS):\n",
    "        # Create test cases\n",
    "        idx_replace_cases = np.random.choice(idx_replace_cases, int(TEST_CASES/2), replace=False)\n",
    "        idx_normal_cases = np.random.choice(idx_normal_cases, int(TEST_CASES/2), replace=False)\n",
    "        test_cases = [*idx_normal_cases, *idx_replace_cases]\n",
    "        results = test_script(METRICS_METHOD, test_round, df_normalized, algos[n], EPISODES, env, ENVIRONMENT_INFO, \n",
    "                              agent_SB, test_cases, TEST_INFO, DATA_FILE, WEAR_THRESHOLD, RESULTS_FILE)\n",
    "        write_test_results(results, RESULTS_FILE)\n",
    "    n += 1\n",
    "\n",
    "### Create a consolidated algorithm wise metrics summary\n",
    "print(80*'-', f'\\n Algorithm level consolidated metrics being reported to file:\\n {METRICS_FILE}\\n', 80*'-')\n",
    "\n",
    "header_columns = [VERSION]\n",
    "write_test_results(header_columns, METRICS_FILE)\n",
    "header_columns = ['Date', 'Time', 'Environment', 'Noise', 'Breakdown_chance', 'Train_data', 'Wear threshold', 'Episodes', 'Terminate on',\n",
    "                  'Test_info', 'Test_cases', 'Metrics_method']\n",
    "write_test_results(header_columns, METRICS_FILE)\n",
    "\n",
    "dt_t = dt.strftime('%H:%M:%S')\n",
    "noise_info = 'None' if ADD_NOISE == 0 else (1/ADD_NOISE)\n",
    "header_info = [dt_d, dt_t, ENVIRONMENT_INFO, noise_info, BREAKDOWN_CHANCE, DATA_FILE, WEAR_THRESHOLD, EPISODES, MILLING_OPERATIONS_MAX, TEST_INFO, TEST_CASES, METRICS_METHOD]\n",
    "write_test_results(header_info, METRICS_FILE)\n",
    "write_test_results([], METRICS_FILE) # leave a blank line\n",
    "\n",
    "print('- Experiment related meta info written')\n",
    "\n",
    "df_algo_results = pd.read_csv(RESULTS_FILE)\n",
    "# algo_metrics = compute_metrics_simple(df_algo_results)\n",
    "algo_metrics = compute_metrics(df_algo_results)\n",
    "\n",
    "write_metrics_report(algo_metrics, METRICS_FILE, 4)\n",
    "write_test_results([], METRICS_FILE) # leave a blank line\n",
    "print('- Algorithm level consolidated metrics reported to file')\n",
    "\n",
    "## ------------------------------------------------------------------------------------------\n",
    "write_test_results(header_columns, CONSOLIDATED_METRICS_FILE)\n",
    "write_test_results(header_info, CONSOLIDATED_METRICS_FILE)\n",
    "write_test_results([], CONSOLIDATED_METRICS_FILE) # leave a blank line\n",
    "write_metrics_report(algo_metrics, CONSOLIDATED_METRICS_FILE, 4)\n",
    "write_test_results([120*'-'], CONSOLIDATED_METRICS_FILE) # leave a blank line\n",
    "print(f'- {CONSOLIDATED_METRICS_FILE} file updated')\n",
    "print(algo_metrics.round(3))\n",
    "print('\\n\\n ================= END OF PROGRAM =================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f8c941c0-893c-45f4-9a5f-e06ac2d56aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
